※Kubernetes는 용어 정리를 잘해야 한다고 한다(팀장님)
■Chapter 15 Kubernetes Helm
-Helm: 쿠버네티스에서 패키지를 관리하기 위한 명령어
-deploy: pod 생성
-쿠버네티스에서 없던 개념인 '차트(쿠버네티스에서의 이미지와 비슷한 개념)'를 모아놓은 것이 '레파지토리'
-RedHat 계열의 yum처럼 Kubenetes에서의 패키지 매니저: Helm
-많은 yaml파일들을 관리하며 이런 yaml파일들의 집합이 Chart(차트는 yaml파일로 이루어져 있다는 것을 알 수 있다)
-v2에서는 Tiller server를 이용하였지만 v3로 넘어와서는 Helm Client에서 직접 Kubenetes API server로 연결하는 방식으로 동작된다
-차트 패키지의 기본 확장자는 tgz이다
-helm에서 변수를 지정할 때에 사용하는 옵션은 --set이다(쿠버네티스에서는 -e였나 그랬다고 한다)
-쿠버네티스에서 이미지를 지정할 때의 옵션인 --image=mysql을 helm에서는 stable/mysql로 입력한다
-pv는 ns에 간섭받지 않지만, pvc는 특정 ns에서 작업하기 때문에 ns를 바꾸면 pv는 보이지만 pvc는 보이지 않는다
-kubectl apply와 kubectl create의 차이점: 
-kubectl exec -it mysql의 pod 이름 으로 접속 후 # mysql -uroot -prootpassword로 접속하여 mydatabase가 있는 지 확인 후 exit
-cat mysql-pv.yaml로 yaml파일의 내용을 확인해본 후 hostPath: path: /opt/mysql 내용을 보면 hostpath가 /opt/mysql이라는 경로에
storage: 2Gi, 2기가를 할당 한다는 뜻이므로 kubectl get pods -o wide 명령어로 mysql이 생성된 node를 확인 후 해당 node 에서 ls /opt로 opt라는 디렉토리
에 mysql이 있는 지 확인해본다
-마스터노드에서 helm del 명령어로 mysql을 삭제해도, mysql가 생성된 노드에서는 ls /opt/mysql/mydatabase를 보면 디렉토리가 남아있는 것을 확인할 수 
있다
-helm fetch stable/mysql-> tar xvzf mysql 1.6.9.tgz로 압축을 해제한 후 tree mysql로 한눈에 보고 helm install mysql ./mysql을 하면
(./mysql이 차트가 되고 이렇게 생성한 디렉토리를 차트로 사용한다)
-port-forward의 개념
-다른 터미널(새로운 탭이나 새로운 터미널을 만든 후)에서 mariadb가 설치되지 않으면 105나 -client, -server등으로 설치해보자
ubuntu 환경이라 apt install mariadb-server -y 명령어로 설치를 했다
ㅁChartMuseum: Chart저장소를 호스팅 하기 위한 오픈 소스 프로젝트(헬름 차트는 쿠버네티스 어플리케이션을 패키지화 하고 버전관리하는데 사용되는
배포 패키지)
-차트뮤지엄의 디렉토리를 생성 후 연결 시킬 때 -- storage가 아닌 --storage (한 줄 밑에 있어 햇깔린다)
chartmuseum --debug --port=8080 --storage="local" --storage-local-rootdir="/chart storage"
다른 터미널에서 curl --data-binary "@mysql-1.7.0.tgz" http://localhost:8080/api/charts를 하여 업로드를 할 수 있었다
명령 프롬프트를 정상화 하고 명령어를 입력하자

■Chapter 16 Kubernetes Monitoring (Prometheus & Grafana)
-모니터링 툴 중 프로메테우스가 압도적인 사용률을 보이는 이유: Kubenetes와 같은 재단이어서
(2016년 Kubernetes 에 이어 두 번째 호스팅 프로젝트로 Cloud Native Computing Foundation 합류) 테스트도 쿠버네티스에서..
-yaml파일들을 apply하고 get pods -o wide에 나와있는 prometheus-deployment의 node의 퍼블릭 IP에 포트 30003번을 입력하여 웹브라우저에서
접속해본다
-생성했던 yaml을 delete만 하면 생성했던 리소스도 삭제가 된다고 한다
kubectl delete -f .yaml

■Chapter 17 Kubernetes Health Check
-probe: 진단 기능
-Health Check types에서 startupProbe는 거의 사용되지 않는다
-liveness: 생존을 확인 후 재시작 / readiness: 동작을 하는지 확인 후 정상적으로 동작하지 않으면 삭제
-liveness 테스트 명령어 중 kill signal은 중지를 하라는 명령문

■Chapter 18 Kubernetes Security
-ingress와 Egress (aws ec2의 인바운드 규칙, 아웃바운드 규칙과 비슷한 것 같다)
-Network Policy Ingress의 설정
1. IPBlock
2. podSelector
3. namespaceSelector
4. Protocal & Port

ㅁIngress ipBlock
-cordon으로 하나의 node를 막아두고 nginx-policy1,2의 yaml파일을 실행하여 하나의 node에서 pod가 생성되게 하자
-같은 네트워크로 묶어 ipblock의 테스트를 하기 위해
-ipblock의 cidr의 주소를 pod에 할당된 ip가 아닌 다른 ip로 입력을 하니(yaml) 같은 node의 같은 대역대의 ip라도
pod1 에서 pod2로 curl을 해도 접속이 되지 않았다

ㅁingress PodSelector
-pod의 label을 바꾸어 같은 네트워크라도 curl을 했을 때 접속이 되지 않았다 (다른 레이블이라 접속이 되지 않았다)

ㅁingress namespaceSelector
-kubectl delete deploy user-deployment -n default 의 명령어로 디폴트라는 네임스페이스의 유저-디플로이먼트라는 디플로이도 삭제할 수 있다
-네임스페이스는 네임스페이스 뿐만 아니라 레이블을 추가하여 ingress를 제한할 수도 있다
namespaceSelector:
matchLabels:
app: namespace-selector-test의 예시가 그렇다(레이블이 네임스페이스 셀렉터 테스트로 매치가 되어야지 접속할 수 있다)

ㅁingress Protocol, Port 설정
-
ㅁEgress 
-ipblock과 protocol, port만 설정가능하다

ㅁ전체 정책 설정
-